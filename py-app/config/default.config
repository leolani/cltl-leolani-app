[cltl.audio]
sampling_rate: 16000
channels: 1
sample_depth: 2
frame_size: 480

audio_resource: cltl.backend.resource.audio
mic_resource: cltl.backend.resource.microphone

[cltl.video]
resolution: VGA
camera_index: 0

[cltl.backend]
### To run locally with system
run_server: True
server_image_url: http://0.0.0.0:8000/host
server_audio_url: http://0.0.0.0:8000/host
### To run on pepper
# run_server: False
# server_image_url: http://192.168.1.176:8000
# server_audio_url: http://192.168.1.176:8000
storage_url: http://0.0.0.0:8000/storage/
audio_storage_path: ./storage/audio
audio_source_buffer: 16
image_storage_path: ./storage/image
image_cache: 32
scenario_topic: cltl.topic.scenario

[cltl.backend.mic]
topic: cltl.topic.microphone

[cltl.backend.image]
topic: cltl.topic.image
rate: 0.2

[cltl.backend.tts]
topic: cltl.topic.text_out

[cltl.backend.text_output]
## Local console output
remote_url:
## Run on pepper
# remote_url: http://192.168.1.176:8000

[cltl.vad]
implementation: webrtc
mic_topic: cltl.topic.microphone
vad_topic: cltl.topic.vad

[cltl.vad.webrtc]
activity_window: 300
activity_threshold: 0.8
allow_gap: 300
padding: 600

[cltl.asr]
implementation: whisper
sampling_rate: 16000
vad_topic: cltl.topic.vad
asr_topic: cltl.topic.text_in

[cltl.asr.google]
sampling_rate: 16000
language: en-GB
hints:

[cltl.asr.whisper]
model: base
language: en

[cltl.asr.wav2vec]
# model: facebook/wav2vec2-large-960h
model: jonatasgrosman/wav2vec2-large-xlsr-53-english

[cltl.asr.speechbrain]
# model: speechbrain/asr-transformer-transformerlm-librispeech
model: speechbrain/asr-wav2vec2-commonvoice-en

[cltl.face_recognition]
implementation: proxy

[cltl.face_recognition.proxy]
start_infra: True

[cltl.face_recognition.events]
image_topic: cltl.topic.image
face_topic: cltl.topic.face_recognition

[cltl.object_recognition]
implementation: proxy

[cltl.object_recognition.proxy]
start_infra: True

[cltl.object_recognition.events]
image_topic: cltl.topic.image
object_topic: cltl.topic.object_recognition

[cltl.vector_id.agg]
distance_threshold: 0.66
storage_path: ./storage/vector_id

[cltl.vector_id.events]
face_topic: cltl.topic.face_recognition
id_topic: cltl.topic.face_id

[cltl.emotion_recognition]
impl: Go

[cltl.emotion_recognition.go]
model: bhadresh-savani/bert-base-go-emotion

[cltl.emotion_recognition.events]
intentions: chat
topic_intention: cltl.topic.intention
topic_input: cltl.topic.chat_text_in
topic_output: cltl.topic.emotion

[cltl.face_emotion_recognition]
implementation: emotic

[cltl.face_emotion_recognition.emotic]
model_context: resources/face_models/model_body1.pth
model_body: resources/face_models/model_context1.pth
model_emotic: resources/face_models/model_emotic1.pth
value_thresholds: resources/face_models/val_thresholds.npy

[cltl.face_emotion_recognition.events]
intentions: chat
topic_intention: cltl.topic.intention
topic_input: cltl.topic.face_recognition
topic_output: cltl.topic.emotion

[cltl.nlp.spacy]
model: en_core_web_sm
entity_relations: nsubj, nsubjpass, dobj, prep, pcomp, acomp

[cltl.nlp.events]
topic_in: cltl.topic.chat_text_in
topic_out: cltl.topic.nlp

[cltl.mention_extraction]
confidence_threshold: 0.8

[cltl.mention_extraction.events]
intentions: chat
topic_intention: cltl.topic.intention
topic_scenario: cltl.topic.scenario
topics_in: cltl.topic.nlp, cltl.topic.face_id, cltl.topic.object_recognition, cltl.topic.emotion
topic_out: cltl.topic.triple_extraction

[cltl.triple_extraction]
implementation: CFGAnalyzer, StanzaQuestionAnalyzer
intentions: chat
topic_intention: cltl.topic.intention
topic_input : cltl.topic.chat_text_in
topic_agent : cltl.topic.text_out
topic_output : cltl.topic.triple_extraction
topic_dialogue_act : cltl.topic.dialogue_act
topic_scenario : cltl.topic.scenario

[cltl.triple_extraction.conversational]
model_path: resources/conversational_triples

[cltl.entity_linking]
address: http://localhost:7200/repositories/sandbox
log_dir: ./storage/rdf
implementations: FaceIDLinker, NamedEntityLinker
#implementations: NamedEntityLinker
topic_scenario : cltl.topic.scenario
topic_input : cltl.topic.triple_extraction
topic_output : cltl.topic.entity_linking

[cltl.brain]
address: http://localhost:7200/repositories/sandbox
log_dir: ./storage/rdf
clear_brain : False
topic_input : cltl.topic.entity_linking
topic_output : cltl.topic.brain_response

[cltl.dialogue_act_classification]
implementation: midas

[cltl.dialogue_act_classification.midas]
model: resources/midas-da-roberta/classifier.pt

[cltl.dialogue_act_classification.events]
intentions: chat
topic_intention: cltl.topic.intention
topic_inputs : cltl.topic.chat_text_in, cltl.topic.text_out
topic_output : cltl.topic.dialogue_act

[cltl.reply_generation]
implementations: SimpleNLGReplier
utterance_types: question, statement, text_mention
thought_options: _complement_conflict, _negation_conflicts, _statement_novelty, _entity_novelty, _subject_gaps, _complement_gaps, _overlaps, _trust
randomness: 0.25
topic_input : cltl.topic.brain_response
topic_output : cltl.topic.text_out
intentions: chat
topic_intention: cltl.topic.intention

[cltl.chat-ui]
name: chat-ui
agent_id: leolani
external_input: True

[cltl.chat-ui.events]
local: True
topic_utterance: cltl.topic.text_in
topic_response: cltl.topic.text_out
topic_scenario : cltl.topic.scenario

[cltl.eliza]
topic_input : cltl.topic.text_in
topic_output : cltl.topic.text_out

[cltl.leolani.friends]
implementation: brain

[cltl.leolani.keyword]
topic_intention: cltl.topic.intention
topic_desire: cltl.topic.desire
topic_text_in : cltl.topic.text_in
topic_text_out : cltl.topic.text_out

[cltl.context]
topic_scenario: cltl.topic.scenario
topic_speaker: cltl.topic.speaker
topic_intention: cltl.topic.intention
topic_desire: cltl.topic.desire
topic_knowledge: cltl.topic.knowledge
topic_object: cltl.topic.object_recognition
topic_vector_id: cltl.topic.face_id

[cltl.monitoring]
topic_object: cltl.topic.object_recognition
topic_vector_id: cltl.topic.face_id
topic_image: cltl.topic.image
topic_text_in: cltl.topic.text_in
topic_text_out : cltl.topic.text_out

[cltl.bdi]
topic_scenario: cltl.topic.scenario
topic_intention: cltl.topic.intention
topic_desire: cltl.topic.desire

[cltl.g2ky]
implementation: visual

[cltl.g2ky.visual]
gaze_images: 3

[cltl.g2ky.events]
intentions: g2ky
topic_intention: cltl.topic.intention
topic_desire: cltl.topic.desire
topic_utterance: cltl.topic.text_in
topic_image: cltl.topic.image
topic_face: cltl.topic.face_recognition
topic_id: cltl.topic.face_id
topic_response: cltl.topic.text_out
topic_speaker: cltl.topic.speaker

[cltl.about]
intentions : chat
topic_intention : cltl.topic.intention
topic_input : cltl.topic.text_in
topic_response : cltl.topic.text_out
topic_forward : cltl.topic.chat_0_text_in

[cltl.visual-responder]
intentions : chat
topic_scenario : cltl.topic.scenario
topic_intentions : cltl.topic.intention
topic_input : cltl.topic.chat_0_text_in
topic_response : cltl.topic.text_out
topic_forward : cltl.topic.chat_text_in

[cltl.leolani]
event_log : ./storage/event_log
brain_log : ./storage/brain
topic_scenario : cltl.topic.scenario
topic_input : cltl.topic.text_in
topic_output : cltl.topic.text_out_leolani

[cltl.leolani.intentions.init]
topic_intention: cltl.topic.intention
topic_desire: cltl.topic.desire
topic_text_in: cltl.topic.text_in
topic_text_out: cltl.topic.text_out
topic_face: cltl.topic.face_recognition
greeting: Do you want to talk to me?

[cltl.leolani.intentions.chat]
intentions : chat
topic_intention: cltl.topic.intention
topic_scenario : cltl.topic.scenario
topic_utterance: cltl.topic.text_in
topic_speaker_mention: cltl.topic.triple_extraction

[cltl.leolani.idresolution]
active: True
topic_speaker: cltl.topic.speaker
topic_knowledge: cltl.topic.knowledge

[cltl.event.kombu]
server: amqp://localhost:5672
exchange: cltl.combot
type: direct
compression: bzip2

[cltl.event_log]
log_dir: ./storage/event_log


[cltl.emissor-data]
path: ./storage/emissor

[cltl.emissor-data.event]
topics: cltl.topic.scenario,
        cltl.topic.image, cltl.topic.microphone,
        cltl.topic.text_in, cltl.topic.text_out, cltl.topic.text_out_replier,
        cltl.topic.face_id, cltl.topic.face_recognition, cltl.topic.object_recognition,
        cltl.topic.emotion, cltl.topic.dialogue_act, cltl.topic.nlp,
        cltl.topic.vad

[environment]
GOOGLE_APPLICATION_CREDENTIALS: config/google_cloud_key.json
